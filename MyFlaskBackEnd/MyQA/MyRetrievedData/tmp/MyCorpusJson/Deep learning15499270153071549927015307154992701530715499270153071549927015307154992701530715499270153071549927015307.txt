{"id": "Deep learning15499270153071549927015307154992701530715499270153071549927015307154992701530715499270153071549927015307.txt", "text": "LSTM RNNs can learn \"Very Deep Learning\" tasks[2] that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates[108] is competitive with traditional speech recognizers on certain tasks. [51]\r\n\r\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences. [118] Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991. Method\tPER (%)\r\nRandomly Initialized RNN[119]\t26.1\r\nBayesian Triphone GMM-HMM\t25.6\r\nHidden Trajectory (Generative) Model\t24.8\r\nMonophone Randomly Initialized DNN\t23.4\r\nMonophone DBN-DNN\t22.4\r\nTriphone GMM-HMM with BMMI Training\t21.7\r\nMonophone DBN-DNN on fbank\t20.7\r\nConvolutional DNN[120]\t20.0\r\nConvolutional DNN w. Heterogeneous Pooling\t18.7\r\nEnsemble DNN/CNN/RNN[121]\t18.3\r\nBidirectional LSTM\t17.9\r\nHierarchical Convolutional Deep Maxout Network[122]\t16.5\r\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003-2007, accelerated progress in eight major areas:[10][74][72]\r\n\r\nScale-up/out and acclerated DNN training and decoding\r\nSequence discriminative training\r\nFeature processing by deep models with solid understanding of the underlying mechanisms\r\nAdaptation of DNNs and related deep models\r\nMulti-task and transfer learning by DNNs and related deep models\r\nCNNs and how to design them to best exploit domain knowledge of speech\r\nRNN and its rich LSTM variants\r\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models. All major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning. [10][123][124][125]\r\n\r\nImage recognition\r\nMain article: Computer vision\r\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available. [126]\r\n\r\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011. [127]\r\n\r\nDeep learning-trained vehicles now interpret 360\u00b0 camera views. [128] Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes. Visual art processing\r\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. "}