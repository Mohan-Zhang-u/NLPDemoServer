{"id": "Artificial neural network15499251521101549925152110.txt", "text": "Choosing a cost function\r\nWhile it is possible to define an ad hoc cost function, frequently a particular cost (function) is used, either because it has desirable properties (such as convexity) or because it arises naturally from a particular formulation of the problem (e.g., in a probabilistic formulation the posterior probability of the model can be used as an inverse cost). Ultimately, the cost function depends on the task. Backpropagation\r\nMain article: Backpropagation\r\nA DNN can be discriminatively trained with the standard backpropagation algorithm. Backpropagation is a method to calculate the gradient of the loss function (produces the cost associated with a given state) with respect to the weights in an ANN. The basics of continuous backpropagation[11][56][57][58] were derived in the context of control theory by Kelley[59] in 1960 and by Bryson in 1961,[60] using principles of dynamic programming. In 1962, Dreyfus published a simpler derivation based only on the chain rule. [61] Bryson and Ho described it as a multi-stage dynamic system optimization method in 1969. [62][63] In 1970, Linnainmaa finally published the general method for automatic differentiation (AD) of discrete connected networks of nested differentiable functions. [64][65] This corresponds to the modern version of backpropagation which is efficient even when the networks are sparse. [11][56][66][67] In 1973, Dreyfus used backpropagation to adapt parameters of controllers in proportion to error gradients. [68] In 1974, Werbos mentioned the possibility of applying this principle to Artificial neural networks,[69] and in 1982, he applied Linnainmaa's AD method to neural networks in the way that is widely used today. [56][70] In 1986, Rumelhart, Hinton and Williams noted that this method can generate useful internal representations of incoming data in hidden layers of neural networks. [71] In 1993, Wan was the first[11] to win an international pattern recognition contest through backpropagation. [72]\r\n\r\nThe weight updates of backpropagation can be done via stochastic gradient descent using the following equation:\r\n\r\n{\\displaystyle w_{ij}(t+1)=w_{ij}(t)+\\eta {\\frac {\\partial C}{\\partial w_{ij}}}+\\xi (t)} {\\displaystyle w_{ij}(t+1)=w_{ij}(t)+\\eta {\\frac {\\partial C}{\\partial w_{ij}}}+\\xi (t)}\r\nwhere, {\\displaystyle \\eta } \\eta  is the learning rate, {\\displaystyle C} C is the cost (loss) function and {\\displaystyle \\xi (t)} \\xi (t) a stochastic term. The choice of the cost function depends on factors such as the learning type (supervised, unsupervised, reinforcement, etc.) and the activation function. For example, when performing supervised learning on a multiclass classification problem, common choices for the activation function and cost function are the softmax function and cross entropy function, respectively. "}