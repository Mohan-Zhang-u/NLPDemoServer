{"id": "Natural language processing1549927015442154992701544215499270154421549927015442.txt", "text": "Named entity recognition (NER)\r\nGiven a stream of text, determine which items in the text map to proper names, such as people or places, and what the type of each such name is (e.g. person, location, organization). Note that, although capitalization can aid in recognizing named entities in languages such as English, this information cannot aid in determining the type of named entity, and in any case is often inaccurate or insufficient. For example, the first word of a sentence is also capitalized, and named entities often span several words, only some of which are capitalized. Furthermore, many other languages in non-Western scripts (e.g. Chinese or Arabic) do not have any capitalization at all, and even languages with capitalization may not consistently use it to distinguish names. For example, German capitalizes all nouns, regardless of whether they are names, and French and Spanish do not capitalize names that serve as adjectives. Natural language generation\r\nConvert information from computer databases or semantic intents into readable human language. Natural language understanding\r\nConvert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semantics formalization. [15]\r\nOptical character recognition (OCR)\r\nGiven an image representing printed text, determine the corresponding text. Question answering\r\nGiven a human-language question, determine its answer. Typical questions have a specific right answer (such as \"What is the capital of Canada? \"), but sometimes open-ended questions are also considered (such as \"What is the meaning of life?\"). Recent works have looked at even more complex questions. [16]\r\nRecognizing Textual entailment\r\nGiven two text fragments, determine if one being true entails the other, entails the other's negation, or allows the other to be either true or false. [17]\r\nRelationship extraction\r\nGiven a chunk of text, identify the relationships among named entities (e.g. who is married to whom). Sentiment analysis (see also multimodal sentiment analysis)\r\nExtract subjective information usually from a set of documents, often using online reviews to determine \"polarity\" about specific objects. It is especially useful for identifying trends of public opinion in the social media, for the purpose of marketing. Topic segmentation and recognition\r\nGiven a chunk of text, separate it into segments each of which is devoted to a topic, and identify the topic of the segment. Word sense disambiguation\r\nMany words have more than one meaning; we have to select the meaning which makes the most sense in context. For this problem, we are typically given a list of words and associated word senses, e.g. from a dictionary or from an online resource such as WordNet. "}