Minimizing this cost using gradient descent for the class of neural networks called multilayer perceptrons (MLP), produces the backpropagation algorithm for training neural networks. Tasks that fall within the paradigm of supervised learning are pattern recognition (also known as classification) and regression (also known as function approximation). The supervised learning paradigm is also applicable to sequential data (e.g., for hand writing, speech and gesture recognition). This can be thought of as learning with a "teacher", in the form of a function that provides continuous feedback on the quality of solutions obtained thus far. Unsupervised learning
In unsupervised learning, some data {\displaystyle \textstyle x} \textstyle x is given and the cost function to be minimized, that can be any function of the data {\displaystyle \textstyle x} \textstyle x and the network's output, {\displaystyle \textstyle f} \textstyle f.

The cost function is dependent on the task (the model domain) and any a priori assumptions (the implicit properties of the model, its parameters and the observed variables). As a trivial example, consider the model {\displaystyle \textstyle f(x)=a} \textstyle f(x)=a where {\displaystyle \textstyle a} \textstyle a is a constant and the cost {\displaystyle \textstyle C=E[(x-f(x))^{2}]} \textstyle C=E[(x-f(x))^{2}]. Minimizing this cost produces a value of {\displaystyle \textstyle a} \textstyle a that is equal to the mean of the data. The cost function can be much more complicated. Its form depends on the application: for example, in compression it could be related to the mutual information between {\displaystyle \textstyle x} \textstyle x and {\displaystyle \textstyle f(x)} \textstyle f(x), whereas in statistical modeling, it could be related to the posterior probability of the model given the data (note that in both of those examples those quantities would be maximized rather than minimized). Tasks that fall within the paradigm of unsupervised learning are in general estimation problems; the applications include clustering, the estimation of statistical distributions, compression and filtering. Reinforcement learning
See also: Stochastic control
In reinforcement learning, data {\displaystyle \textstyle x} \textstyle x are usually not given, but generated by an agent's interactions with the environment. At each point in time {\displaystyle \textstyle t} \textstyle t, the agent performs an action {\displaystyle \textstyle y_{t}} \textstyle y_{t} and the environment generates an observation {\displaystyle \textstyle x_{t}} \textstyle x_{t} and an instantaneous cost {\displaystyle \textstyle c_{t}} \textstyle c_{t}, according to some (usually unknown) dynamics. The aim is to discover a policy for selecting actions that minimizes some measure of a long-term cost, e.g., the expected cumulative cost. The environment's dynamics and the long-term cost for each policy are usually unknown, but can be estimated. 